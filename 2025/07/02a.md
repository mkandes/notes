# How to install and run MLCFlow (on Expanse)

### Option 1: Using JupyterLab for interactive development and testing

Before starting a new interactive development session to continue your MLCFlow exploration and testing work, you may want to first remove cached configuration and log information placed in your HOME directory.

*COMMAND*
```
rm -rf .galyleo/ .conda/ .nv/ .local/ .ipython/ .jupyter/ .cache/ .mlc-log.txt mlc-run-script-versions.json version_info.json hardware/
```
*OUTPUT*

```
N/A
```

Make any final changes to your conda environment YAML file prior to launching your JupyterLab with galyleo.

*FILE*
```
name: mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu

channels:
  - conda-forge

dependencies:
  - python=3.12
  - pip
  - wheel
  - numpy=1.26.4=py312heda63a1_0
  - opencv=4.11.0=headless_py312hcb6eebc_9
  - pillow=11.2.1=py312h80c1187_0
  - onnxruntime=1.22.0=py312h2a9cbd2_0_cpu
  - jupyterlab
  - matplotlib
  - networkx
#  - pip:
#    - mlcommons-loadgen==5.1.0

variables:
  ENV_VAR_X: 'MLC_REPOS'
```

When ready, launch your JupyterLab session on Expanse with galyleo. First, make sure galyleo is in your PATH.


*COMMAND*
```
export PATH="/cm/shared/apps/sdsc/galyleo:${PATH}"
```
*OUTPUT*
```
N/A
```

Then run your launch command.

*COMMAND*
```
galyleo launch --account use300 --partition ind-compute --cpus 128 --memory 242 --time-limit 08:00:00 --conda-yml mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu.yaml
```
*OUTPUT*
```
[mkandes@login02 ~]$ galyleo launch --account use300 --partition ind-compute --cpus 128 --memory 242 --time-limit 08:00:00 --conda-yml mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu.yaml
Preparing galyleo for launch into Jupyter orbit ...
Listing all launch parameters ...
  command-line options       : values
    -A | --account           : use300
    -R | --reservation       : 
    -p | --partition         : ind-compute
    -q | --qos               : 
    -N | --nodes             : 1
    -c | --cpus              : 128
    -m | --memory            : 242 GB
    -g | --gpus              : 
       | --gres              : 
    -t | --time-limit        : 08:00:00
    -C | --constraint        : 
    -i | --interface         : lab
    -d | --notebook-dir      : 
       | --scratch-dir       : "/scratch/${USER}/job_${SLURM_JOB_ID}"
    -e | --env-modules       : singularitypro
       | --append-modulepath : 
    -s | --sif               : 
    -B | --bind              : 
       | --nv                : 
       | --conda-init        : 
       | --conda-env         : 
       | --conda-yml         : /home/mkandes/mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu.yaml
       | --conda-version     : latest
       | --mamba             : false
       | --cache             : false
       | --spark-home        : 
       | --disable-checklist : false
       | --checklist-timeout : 10 s
    -Q | --quiet             : 1
Your token is 
monotone-sincere-slouchy
200
Generating Jupyter launch script ...
md5sum: mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu.md5: No such file or directory
Submitted Jupyter launch script to Slurm. Your SLURM_JOB_ID is 40829790.
Success! Token linked to jobid.
Please copy and paste the HTTPS URL provided below into your web browser.
Do not share this URL with others. It is the password to your Jupyter notebook session.
Your Jupyter notebook session will begin once compute resources are allocated to your job by the scheduler.
https://monotone-sincere-slouchy.expanse-user-content.sdsc.edu/?token=4186c3a33f9fc6fdad5f
[mkandes@login02 ~]$
```

When your JupyterLab session begins, you can use the Terminal application to interactively develop and test your MLCFlow deployment and MLPerf Inference Benchmark. To speed up your development process, make sure to set the following environment variable before installing MLCFlow to redirect the caching of your MLCFlow repo(s) to the local /scratch disk available on each Expanse compute node.

*COMMAND*
```
export MLC_REPOS="${SLURM_TMPDIR}/MLC/repos"
```
*OUTPUT*
```
N/A
```

Next, install MLCFlow with pip.

*COMMAND*
```
pip install mlcflow
```
*OUTPUT*
```
[mkandes@exp-15-02 ~]$ pip install mlcflow
Collecting mlcflow
  Downloading mlcflow-1.0.18-py3-none-any.whl.metadata (19 kB)
Requirement already satisfied: requests in /scratch/mkandes/job_40829790/miniconda3/envs/mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu/lib/python3.12/site-packages (from mlcflow) (2.32.4)
Requirement already satisfied: pyyaml in /scratch/mkandes/job_40829790/miniconda3/envs/mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu/lib/python3.12/site-packages (from mlcflow) (6.0.2)
Collecting giturlparse (from mlcflow)
  Downloading giturlparse-0.12.0-py2.py3-none-any.whl.metadata (4.5 kB)
Collecting colorama (from mlcflow)
  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
Requirement already satisfied: charset_normalizer<4,>=2 in /scratch/mkandes/job_40829790/miniconda3/envs/mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu/lib/python3.12/site-packages (from requests->mlcflow) (3.4.2)
Requirement already satisfied: idna<4,>=2.5 in /scratch/mkandes/job_40829790/miniconda3/envs/mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu/lib/python3.12/site-packages (from requests->mlcflow) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /scratch/mkandes/job_40829790/miniconda3/envs/mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu/lib/python3.12/site-packages (from requests->mlcflow) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /scratch/mkandes/job_40829790/miniconda3/envs/mlperf-inference-vision-image-classification-resnet50-imagenet-python-edge-onnxruntime-cpu/lib/python3.12/site-packages (from requests->mlcflow) (2025.6.15)
Downloading mlcflow-1.0.18-py3-none-any.whl (47 kB)
Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Downloading giturlparse-0.12.0-py2.py3-none-any.whl (15 kB)
Installing collected packages: giturlparse, colorama, mlcflow
Successfully installed colorama-0.4.6 giturlparse-0.12.0 mlcflow-1.0.18
[mkandes@exp-15-02 ~]$
```

Run the following mlc command to check the install is working and that the repos will be cached to local /scratch.
*COMMAND*
```
mlc list repo
```
*OUTPUT*
```
[mkandes@exp-15-02 ~]$ mlc list repo
[2025-07-02 07:35:37,985 action.py:194 INFO] - Created repos.json in /scratch/mkandes/job_40829790/MLC and initialised with local cache folder path: /scratch/mkandes/job_40829790/MLC/repos/local
[2025-07-02 07:35:37,994 repo_action.py:467 INFO] - Listing all repositories.

Repositories:
-------------
- Alias: local
  Path:  /scratch/mkandes/job_40829790/MLC/repos/local

-------------
[2025-07-02 07:35:37,995 repo_action.py:474 INFO] - Repository listing ended
[mkandes@exp-15-02 ~]$
```

Now, prior to installing the mlc-scripts to run your MLPerf inference benchmark testing, use the interactive session in your JupyterLab Terminal to consider how to install other software packages via conda. e.g., you can search for additional conda packages available in the conda-forge (and nvidia) channel(s) with the following command.

*COMMAND*
```
conda search cuda-nvcc -c conda-forge -c nvidia
```
*OUTPUT*
```
[mkandes@exp-15-02 ~]$ conda search cuda-nvcc -c conda-forge -c nvidia
Loading channels: done
# Name                       Version           Build  Channel             
cuda-nvcc                    11.3.58      h2467b9f_0  nvidia              
cuda-nvcc                    11.4.48               0  nvidia              
cuda-nvcc                    11.4.48      h7efc363_0  nvidia              
cuda-nvcc                   11.4.100               0  nvidia              
cuda-nvcc                   11.4.100      hcdea6f0_0  nvidia              
cuda-nvcc                   11.4.120               0  nvidia              
cuda-nvcc                   11.4.120      hf9cfa5c_0  nvidia              
....    
cuda-nvcc                    12.8.93      hcdd1206_1  conda-forge         
cuda-nvcc                    12.8.93      hcdd1206_2  conda-forge         
cuda-nvcc                    12.9.41               0  nvidia              
cuda-nvcc                    12.9.41      hcdd1206_0  conda-forge         
cuda-nvcc                    12.9.86               0  nvidia              
cuda-nvcc                    12.9.86      hcdd1206_0  conda-forge         
cuda-nvcc                    12.9.86      hcdd1206_1  conda-forge         
[mkandes@exp-15-02 ~]$
```
You can also search and compare information about available conda packages via the web at https://anaconda.org/search. 
