# MLPerf Inference Benchmark Suite - NLP/BERT/SQuAD

| Area     | Task             | Model          | Dataset              | QSL Size | Quality                  | Latency (ms) |
| -------- | ---------------- | -------------- | -------------------- | -------- | ------------------------ | ------------ | 
| Vision   | Classification   | ResNet-50 v1.5 | ImageNet (224x224)   | 1024     | 99% of FP32 (76.46%)     | 15           |
| Vision   | Object detection | RetinaNet      | OpenImages (800x800) | 64       | 99% of FP32 (0.3755 mAP) | 100          |
| Vision   | Segmentation     | 3D U-Net       | KiTS 2019            | 42       | 99% of FP32 and 99.9% of FP32 (0.86330 mean DICE score) | N/A |
| Language | Processing       | BERT           | SQuAD v1.1           | 10833    | 99% of FP32 and 99.9% of FP32 (f1_score=90.874%) | 130 ms |

* For performance runs, the LoadGen will select queries uniformly at 
  random (with replacement) from a test set. The minimum size of the 
  performance test set for each benchmark is listed as 'QSL Size' in the 
  table above. However, the accuracy test must be run with one copy of 
  the MLPerf specified validation dataset.

Minimum requirements for an MLPerf Inference: Datacenter system
- A datacenter system must use ECC in their DRAM and HBM memories, 
  and ECC must be enabled for all performance and accuracy runs included 
  with a submission. No requirements are imposed on SRAM.
- A datacenter system must be equipped with all the necessary networking 
  required by the system architecture described in the LoadGen Operation 
  section.  The details of the networking components must be described 
  in the appropriate field of the system description. All necessary 
  networking must be populated, if power is measured along with performance.

```
[mkandes@login01 ~]$ srun --account use300 --partition gpu-debug --nodes 1 --ntasks-per-node 1 --cpus-per-task 10 --mem 93G --gpus 1 --time=00:30:00 --wait=0 --pty bash
srun: job 25963966 queued and waiting for resources
srun: job 25963966 has been allocated resources
[mkandes@exp-7-59 ~]$ nvidia-smi --ecc-config=1
ECC support is already Enabled for GPU 00000000:18:00.0.
All done.
[mkandes@exp-7-59 ~]$
```

Steps to running BERT:

1. Setup TensorFlow, PyTorch, and/or ONNX (conda) environments
2. Install LoadGen within those environments
   https://github.com/mlcommons/inference/blob/master/loadgen/README_BUILD.md

PyTorch example install ...

```
[mkandes@login02 ~]$ srun --partition=gpu-debug --account=use300 --nodes=1 --ntasks-per-node=10 --cpus-per-task=1 --mem=92G --gpus=1 --time=00:30:00 --wait=0 --pty /bin/bash
srun: job 25980356 queued and waiting for resources
srun: job 25980356 has been allocated resources
[mkandes@exp-7-59 ~]$ conda env list
# conda environments:
#
base                     /home/mkandes/software/miniconda3/py311_23.9.0-0-Linux-x86_64
pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0     /home/mkandes/software/miniconda3/py311_23.9.0-0-Linux-x86_64/envs/pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0
tensorflow-2.12.0-gpu_py311h65739b5_0     /home/mkandes/software/miniconda3/py311_23.9.0-0-Linux-x86_64/envs/tensorflow-2.12.0-gpu_py311h65739b5_0

[mkandes@exp-7-59 ~]$ conda activate pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 ~]$ conda list | absl-py
bash: absl-py: command not found
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 ~]$ conda list | grep absl-py
absl-py                   1.4.0           py311h06a4308_0  
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 ~]$ conda list | grep numpy
numpy                     1.26.0          py311h08b1b3b_0  
numpy-base                1.26.0          py311hf175353_0  
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 ~]$ cd software/pytorch/
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 pytorch]$ ls
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 pytorch]$ mkdir benchmarks
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 pytorch]$ cd benchmarks/
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 benchmarks]$ mkdir mlperf
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 benchmarks]$ cd mlperf/
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 mlperf]$
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 mlperf]$ git clone --recurse-submodules https://github.com/mlcommons/inference.git mlperf_inference
Cloning into 'mlperf_inference'...
remote: Enumerating objects: 9839, done.
remote: Counting objects: 100% (17/17), done.
remote: Compressing objects: 100% (17/17), done.
^Cfetch-pack: unexpected disconnect while reading sideband packet

(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 mlperf]$ ls
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 mlperf]$ git clone --recurse-submodules https://github.com/mlcommons/inference.git
Cloning into 'inference'...
remote: Enumerating objects: 9839, done.
remote: Counting objects: 100% (17/17), done.
remote: Compressing objects: 100% (17/17), done.
remote: Total 9839 (delta 1), reused 4 (delta 0), pack-reused 9822
Receiving objects: 100% (9839/9839), 426.94 MiB | 12.84 MiB/s, done.
Resolving deltas: 100% (5787/5787), done.
Updating files: 100% (450/450), done.
Submodule 'language/bert/DeepLearningExamples' (https://github.com/NVIDIA/DeepLearningExamples.git) registered for path 'language/bert/DeepLearningExamples'
Submodule 'third_party/pybind' (https://github.com/pybind/pybind11.git) registered for path 'third_party/pybind'
Submodule 'vision/medical_imaging/3d-unet-brats19/nnUnet' (https://github.com/MIC-DKFZ/nnUNet.git) registered for path 'vision/medical_imaging/3d-unet-brats19/nnUnet'
Cloning into '/home/mkandes/software/pytorch/benchmarks/mlperf/inference/language/bert/DeepLearningExamples'...
remote: Enumerating objects: 33328, done.        
remote: Counting objects: 100% (4888/4888), done.        
remote: Compressing objects: 100% (1557/1557), done.        
remote: Total 33328 (delta 3583), reused 3367 (delta 3325), pack-reused 28440        
Receiving objects: 100% (33328/33328), 108.17 MiB | 30.33 MiB/s, done.
Resolving deltas: 100% (23754/23754), done.
Cloning into '/home/mkandes/software/pytorch/benchmarks/mlperf/inference/third_party/pybind'...
remote: Enumerating objects: 27212, done.        
remote: Counting objects: 100% (7883/7883), done.        
remote: Compressing objects: 100% (589/589), done.        
remote: Total 27212 (delta 7521), reused 7333 (delta 7282), pack-reused 19329        
Receiving objects: 100% (27212/27212), 10.01 MiB | 15.64 MiB/s, done.
Resolving deltas: 100% (19415/19415), done.
Cloning into '/home/mkandes/software/pytorch/benchmarks/mlperf/inference/vision/medical_imaging/3d-unet-brats19/nnUnet'...
remote: Enumerating objects: 11164, done.        
remote: Counting objects: 100% (219/219), done.        
remote: Compressing objects: 100% (128/128), done.        
remote: Total 11164 (delta 113), reused 178 (delta 89), pack-reused 10945        
Receiving objects: 100% (11164/11164), 5.47 MiB | 15.55 MiB/s, done.
Resolving deltas: 100% (8501/8501), done.
Submodule path 'language/bert/DeepLearningExamples': checked out 'b03375bd6c2c5233130e61a3be49e26d1a20ac7c'
Submodule 'PyTorch/SpeechRecognition/Jasper/external/tensorrt-inference-server' (https://github.com/NVIDIA/tensorrt-inference-server.git) registered for path 'language/bert/DeepLearningExamples/PyTorch/SpeechRecognition/Jasper/external/tensorrt-inference-server'
Submodule 'PyTorch/Translation/Transformer/cutlass' (https://github.com/NVIDIA/cutlass.git) registered for path 'language/bert/DeepLearningExamples/PyTorch/Translation/Transformer/cutlass'
Cloning into '/home/mkandes/software/pytorch/benchmarks/mlperf/inference/language/bert/DeepLearningExamples/PyTorch/SpeechRecognition/Jasper/external/tensorrt-inference-server'...
remote: Enumerating objects: 43822, done.        
remote: Counting objects: 100% (1755/1755), done.        
remote: Compressing objects: 100% (799/799), done.        
remote: Total 43822 (delta 1123), reused 1387 (delta 913), pack-reused 42067        
Receiving objects: 100% (43822/43822), 30.68 MiB | 31.99 MiB/s, done.
Resolving deltas: 100% (31191/31191), done.
Cloning into '/home/mkandes/software/pytorch/benchmarks/mlperf/inference/language/bert/DeepLearningExamples/PyTorch/Translation/Transformer/cutlass'...
remote: Enumerating objects: 22330, done.        
remote: Counting objects: 100% (5347/5347), done.        
remote: Compressing objects: 100% (605/605), done.        
remote: Total 22330 (delta 4923), reused 4776 (delta 4742), pack-reused 16983        
Receiving objects: 100% (22330/22330), 30.99 MiB | 22.22 MiB/s, done.
Resolving deltas: 100% (16789/16789), done.
Submodule path 'language/bert/DeepLearningExamples/PyTorch/SpeechRecognition/Jasper/external/tensorrt-inference-server': checked out '71f0771cb8cb2a2eb1c6a9433f9a56dd1f206c96'
Submodule path 'language/bert/DeepLearningExamples/PyTorch/Translation/Transformer/cutlass': checked out 'ed2ed4d667ce95e1371bd62db32b6a114e774336'
Submodule 'tools/external/googletest' (https://github.com/google/googletest.git) registered for path 'language/bert/DeepLearningExamples/PyTorch/Translation/Transformer/cutlass/tools/external/googletest'
Cloning into '/home/mkandes/software/pytorch/benchmarks/mlperf/inference/language/bert/DeepLearningExamples/PyTorch/Translation/Transformer/cutlass/tools/external/googletest'...
remote: Enumerating objects: 27018, done.        
remote: Counting objects: 100% (57/57), done.        
remote: Compressing objects: 100% (40/40), done.        
remote: Total 27018 (delta 20), reused 34 (delta 13), pack-reused 26961        
Receiving objects: 100% (27018/27018), 12.46 MiB | 22.31 MiB/s, done.
Resolving deltas: 100% (20050/20050), done.
Submodule path 'language/bert/DeepLearningExamples/PyTorch/Translation/Transformer/cutlass/tools/external/googletest': checked out '9077ec7efe5b652468ab051e93c67589d5cb8f85'
Submodule path 'third_party/pybind': checked out '25abf7efba0b2990f5a6dfb0a31bc65c0f2f4d17'
Submodule 'tools/clang' (https://github.com/wjakob/clang-cindex-python3) registered for path 'third_party/pybind/tools/clang'
Cloning into '/home/mkandes/software/pytorch/benchmarks/mlperf/inference/third_party/pybind/tools/clang'...
remote: Enumerating objects: 368, done.        
remote: Counting objects: 100% (13/13), done.        
remote: Compressing objects: 100% (10/10), done.        
remote: Total 368 (delta 3), reused 10 (delta 3), pack-reused 355        
Receiving objects: 100% (368/368), 159.34 KiB | 3.89 MiB/s, done.
Resolving deltas: 100% (154/154), done.
Submodule path 'third_party/pybind/tools/clang': checked out '6a00cbc4a9b8e68b71caf7f774b3f9c753ae84d5'
Submodule path 'vision/medical_imaging/3d-unet-brats19/nnUnet': checked out 'b38c69b345b2f60cd0d053039669e8f988b0c0af'
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 mlperf]$ CFLAGS="-std=c++14 -O3" python3 -m pip install .
ERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 mlperf]$ cd inference/loadgen/
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 loadgen]$ CFLAGS="-std=c++14 -O3" python3 -m pip install .
Processing /home/mkandes/software/pytorch/benchmarks/mlperf/inference/loadgen
  Preparing metadata (setup.py) ... error
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/home/mkandes/software/pytorch/benchmarks/mlperf/inference/loadgen/setup.py", line 31, in <module>
          from pybind11 import get_include
      ModuleNotFoundError: No module named 'pybind11'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 loadgen]$ conda install pybind11
Collecting package metadata (current_repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: /home/mkandes/software/miniconda3/py311_23.9.0-0-Linux-x86_64/envs/pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0

  added / updated specs:
    - pybind11


The following NEW packages will be INSTALLED:

  pybind11           pkgs/main/linux-64::pybind11-2.10.4-py311hdb19cb5_0 
  pybind11-global    pkgs/main/linux-64::pybind11-global-2.10.4-py311hdb19cb5_0 


Proceed ([y]/n)? y
Downloading and Extracting Packages:

Preparing transaction: done
Verifying transaction: done
Executing transaction: done
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 loadgen]$ CFLAGS="-std=c++14 -O3" python3 -m pip install .
Processing /home/mkandes/software/pytorch/benchmarks/mlperf/inference/loadgen
  Preparing metadata (setup.py) ... done
Building wheels for collected packages: mlperf-loadgen
  Building wheel for mlperf-loadgen (setup.py) ... done
  Created wheel for mlperf-loadgen: filename=mlperf_loadgen-3.1-cp311-cp311-linux_x86_64.whl size=400649 sha256=41ed4f3d01ca70607f4b3e8105acecb12cad6e82d627969fbd24828eb34acac0
  Stored in directory: /tmp/pip-ephem-wheel-cache-k7h4j3ph/wheels/70/8e/b8/02b36a945b8f1beb843520bed1be4e351bc1b73ffbf2f56c0b
Successfully built mlperf-loadgen
Installing collected packages: mlperf-loadgen
Successfully installed mlperf-loadgen-3.1
(pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0) [mkandes@exp-7-59 loadgen]$ python3
Python 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import mlperf_loadgen
>>> mlperf_loadgen.__version__
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: module 'mlperf_loadgen' has no attribute '__version__'
>>> mlperf_loadgen.__file__
'/home/mkandes/software/miniconda3/py311_23.9.0-0-Linux-x86_64/envs/pytorch-2.1.0-py3.11_cuda11.8_cudnn8.7.0_0/lib/python3.11/site-packages/mlperf_loadgen.cpython-311-x86_64-linux-gnu.so'
>>>
```



