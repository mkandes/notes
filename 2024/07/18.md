# REHS Meeting Notes

MLPerf Training Benchmark Results v1.0 - https://github.com/mlcommons/training_results_v1.0

The run the `run_pretrining.py` script, it requires you to install the `mlperf_logging` python modele/library. It's GitHub repo can be found here: https://github.com/mlcommons/logging. To install, you first clone the repository to the same working directory where you cloned the `training` repo with the BERT reference implementation.

```
git clone https://github.com/mlcommons/logging.git
```

```
/home/mkandes/projects/rehs/2024/nlp
[mkandes@login02 nlp]$ ls training/
benchmark_readme_template.md  install_cuda_docker.sh  object_detection      retired_benchmarks
CONTRIBUTING.md               language_model          README.md             rnn_speech_recognition
graph_neural_network          large_language_model    recommendation        single_stage_detector
image_classification          LICENSE.md              recommendation_v2     stable_diffusion
image_segmentation            llama2_70b_lora         reference_results.md
[mkandes@login02 nlp]$ ls logging/
CONTRIBUTING.md  mlperf_logging           RELEASING.md                 verify_for_v1.0_training.sh
LICENSE.md       mlperf_logging.egg-info  setup.py                     VERSION
log_parsers      pack_submission.sh       system_description
MANIFEST.in      README.md                verify_for_v0.7_training.sh
[mkandes@login02 nlp]$
```
Next, change directories to the `logging` repo and then checkout version `1.0.0` of the library.

```
cd logging/
git checkout 1.0.0
```
Go ahead and start an interactive session on your `gpu-debug` node with 1 GPU ...

```
srun --partition=gpu-debug --pty --account=use300 --nodes=1 --ntasks-per-node=1 --cpus-per-task=10 --mem=92G --gpus=1 --time=00:30:00 --wait=0 --export=ALL /bin/bash
```
