### Project #1: Optimizing the Deployment of Scientific Software on High-Performance Computing Systems via the [Spack Package Manager](https://spack.io)

Goals:
1. Determine what software modules are used on [Expanse](https://www.sdsc.edu/services/hpc/expanse) from the [Lmod](https://lmod.readthedocs.io/en/latest/index.html) tracking data available
2. Determine the compute resources that were requested by each batch job run on Expanse from [Slurm's](https://en.wikipedia.org/wiki/Slurm_Workload_Manager) [sacct](https://slurm.schedmd.com/sacct.html) job accounting database
3. Determine the software modules loaded for each job on Expanse
4. Determine what software was utilized on [Comet](https://www.sdsc.edu/support/user_guides/comet.html) using the job script database

Software to use:
1. [Miniconda](https://docs.anaconda.com/miniconda)
2. [Python](https://en.wikipedia.org/wiki/Python_(programming_language))
3. [Pandas](https://en.wikipedia.org/wiki/Pandas_(software))
4. [Matplotlib](https://en.wikipedia.org/wiki/Matplotlib)


### Project #2: Computer Vision and Deep Learning Benchmarks

Goals:
1. Derive a new computer vision dataset based on the [ImageNet Large Scale Visual Recognition Challenge 2012 (ILSVRC2012)](https://image-net.org/challenges/LSVRC/2012/) dataset by replicating a 'larger' version of the [CIFAR-10 dataset](https://en.wikipedia.org/wiki/CIFAR-10)
2. Create a modified version of existing image classification training benchamrk to utilize the new dataset
3. Explore the use of different file formats for repackaging the raw JPEG dataset to optimize training performance
  - HDF5
  - TFRecords


### Project #3: Natural Language Question Answering with [BERT](https://en.wikipedia.org/wiki/BERT_(language_model))
