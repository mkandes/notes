# Voyager - Gaudi2 Testing

At this time, Habana's [torchvision implementation](https://github.com/HabanaAI/Model-References/tree/master/PyTorch/computer_vision/classification/torchvision) of the MLPerf Training benchmark for image classification is failing due to an unknown critical error when run on Gaudi1.

```
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
Namespace(data_path='/scratch/habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-1h205a-pmmv8', dl_time_exclude=False, model='resnet50', device='hpu', batch_size=256, epochs=90, epochs_between_evals=1, eval_offset_epochs=0, dl_worker_type='HABANA', workers=6, process_per_node=8, hls_type='HLS1', lr=0.1, lars_base_learning_rate=9.0, lars_end_learning_rate=0.0001, lars_warmup_epochs=3, lars_decay_epochs=36, momentum=0.9, weight_decay=0.0001, lars_weight_decay=5e-05, lr_step_size=30, custom_lr_values=[0.1, 0.01, 0.001, 0.0001], custom_lr_milestones=[0, 30, 60, 80], lr_gamma=0.1, label_smoothing=0.0, print_freq=20, output_dir='.', channels_last=False, resume='', start_epoch=0, seed=123, cache_dataset=False, sync_bn=False, test_only=False, pretrained=False, use_torch_compile=True, no_compiled_autograd=False, hpu_graphs=True, optimizer='sgd', enable_tensorboard_logging=False, force_native_sgd=False, apex=False, apex_opt_level='O1', world_size=1, dist_url='env://', num_train_steps=9223372036854775807, num_eval_steps=9223372036854775807, save_checkpoint=False, save_model=False, run_lazy_mode=False, deterministic=True, profile=False, profile_steps='0', is_autocast=True, rank=-1, local_rank=-1, distributed=False)
Loading data
Loading training data
Took 2.989082098007202
Loading validation data
Creating samplers
Running with Habana aeon DataLoader
Running with Habana aeon DataLoader
Creating model
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Synapse detected a device critical error that requires a restart. Killing process in 5 seconds (hl: 1) 20:26:34 [please check log files for dfa cause]
/bin/bash: line 44: 54063 Killed                  python3 -u train.py --dl-worker-type 'HABANA' --batch-size 256 --model 'resnet50' --device 'hpu' --workers 6 --print-freq 20 --dl-time-exclude 'False' --deterministic --data-path "${DATASET_DESTINATION_DIR}" --epochs 90 --autocast --lr 0.1 --custom-lr-values 0.1 0.01 0.001 0.0001 --custom-lr-milestones 0 30 60 80 --run-lazy-mode 'False' --use_torch_compile
real 23.68
user 22.26
sys 11.64
```
