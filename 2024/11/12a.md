# Voyager - Gaudi2 Testing

At this time, Habana's [torchvision implementation](https://github.com/HabanaAI/Model-References/tree/master/PyTorch/computer_vision/classification/torchvision) of the MLPerf Training benchmark for image classification is failing due to an unknown critical error when run on Gaudi1. It is bleived that this may be a memory-related problem when running multiple instances of the benchmark on a given Voyager node. 

```
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
Namespace(data_path='/scratch/habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-1h205a-pmmv8', dl_time_exclude=False, model='resnet50', device='hpu', batch_size=256, epochs=90, epochs_between_evals=1, eval_offset_epochs=0, dl_worker_type='HABANA', workers=6, process_per_node=8, hls_type='HLS1', lr=0.1, lars_base_learning_rate=9.0, lars_end_learning_rate=0.0001, lars_warmup_epochs=3, lars_decay_epochs=36, momentum=0.9, weight_decay=0.0001, lars_weight_decay=5e-05, lr_step_size=30, custom_lr_values=[0.1, 0.01, 0.001, 0.0001], custom_lr_milestones=[0, 30, 60, 80], lr_gamma=0.1, label_smoothing=0.0, print_freq=20, output_dir='.', channels_last=False, resume='', start_epoch=0, seed=123, cache_dataset=False, sync_bn=False, test_only=False, pretrained=False, use_torch_compile=True, no_compiled_autograd=False, hpu_graphs=True, optimizer='sgd', enable_tensorboard_logging=False, force_native_sgd=False, apex=False, apex_opt_level='O1', world_size=1, dist_url='env://', num_train_steps=9223372036854775807, num_eval_steps=9223372036854775807, save_checkpoint=False, save_model=False, run_lazy_mode=False, deterministic=True, profile=False, profile_steps='0', is_autocast=True, rank=-1, local_rank=-1, distributed=False)
Loading data
Loading training data
Took 2.989082098007202
Loading validation data
Creating samplers
Running with Habana aeon DataLoader
Running with Habana aeon DataLoader
Creating model
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Synapse detected a device critical error that requires a restart. Killing process in 5 seconds (hl: 1) 20:26:34 [please check log files for dfa cause]
/bin/bash: line 44: 54063 Killed                  python3 -u train.py --dl-worker-type 'HABANA' --batch-size 256 --model 'resnet50' --device 'hpu' --workers 6 --print-freq 20 --dl-time-exclude 'False' --deterministic --data-path "${DATASET_DESTINATION_DIR}" --epochs 90 --autocast --lr 0.1 --custom-lr-values 0.1 0.01 0.001 0.0001 --custom-lr-milestones 0 30 60 80 --run-lazy-mode 'False' --use_torch_compile
real 23.68
user 22.26
sys 11.64
```

However, the benchmark run successfully on a single Gaudi2 with different hyperparameter configurations. Only a few runs have failed thus far.

```
Epoch: [0]  [5000/5005]  eta: 0:00:00  lr: 0.1  img/s: 6269.159464984836  loss: 4.0255 (5.2142)  acc1: 19.9219 (9.0234)  acc5: 42.9688 (21.9109)  time: 0.0408  data: 0.0201
Epoch: [0] Total time: 0:03:44
Warning: Decoder updated User configured Interpolation from Bilinear to Bicubic
/usr/local/lib/python3.10/dist-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/home/mkandes/software/habana/gaudi/1.18.0/Model-References/PyTorch/computer_vision/classification/torchvision/utils.py:184: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  pred_cpu = torch.tensor(pred, device='cpu')
Traceback (most recent call last):
  File "/home/mkandes/software/habana/gaudi/1.18.0/Model-References/PyTorch/computer_vision/classification/torchvision/train.py", line 701, in <module>
    main(args)
  File "/home/mkandes/software/habana/gaudi/1.18.0/Model-References/PyTorch/computer_vision/classification/torchvision/train.py", line 514, in main
    evaluate(model_for_eval, criterion, data_loader_test, device=device,
  File "/home/mkandes/software/habana/gaudi/1.18.0/Model-References/PyTorch/computer_vision/classification/torchvision/train.py", line 145, in evaluate
    acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))
  File "/home/mkandes/software/habana/gaudi/1.18.0/Model-References/PyTorch/computer_vision/classification/torchvision/utils.py", line 184, in accuracy
    pred_cpu = torch.tensor(pred, device='cpu')
RuntimeError: [Rank:0] FATAL ERROR :: MODULE:PT_SYNHELPER workspace Allocation of size ::1645856000 failed!
real 263.28
user 636.33
sys 170.71
```

Unfortuantely, multi-card, single-node configurations are also failing on Gaudi2. 

```
[habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh:54105] MCW rank 1 bound to socket 0[core 10[hwt 0-1]], socket 0[core 11[hwt 0-1]], socket 0[core 12[hwt 0-1]], socket 0[core 13[hwt 0-1]], socket 0[core 14[hwt 0-1]], socket 0[core 15[hwt 0-1]], socket 0[core 16[hwt 0-1]], socket 0[core 17[hwt 0-1]], socket 0[core 18[hwt 0-1]], socket 0[core 19[hwt 0-1]]: [../../../../../../../../../../BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/../../../../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..]
[habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh:54105] MCW rank 2 bound to socket 0[core 20[hwt 0-1]], socket 0[core 21[hwt 0-1]], socket 0[core 22[hwt 0-1]], socket 0[core 23[hwt 0-1]], socket 0[core 24[hwt 0-1]], socket 0[core 25[hwt 0-1]], socket 0[core 26[hwt 0-1]], socket 0[core 27[hwt 0-1]], socket 0[core 28[hwt 0-1]], socket 0[core 29[hwt 0-1]]: [../../../../../../../../../../../../../../../../../../../../BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/../../../../../../../../../..][../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..]
[habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh:54105] MCW rank 3 bound to socket 0[core 30[hwt 0-1]], socket 0[core 31[hwt 0-1]], socket 0[core 32[hwt 0-1]], socket 0[core 33[hwt 0-1]], socket 0[core 34[hwt 0-1]], socket 0[core 35[hwt 0-1]], socket 0[core 36[hwt 0-1]], socket 0[core 37[hwt 0-1]], socket 0[core 38[hwt 0-1]], socket 0[core 39[hwt 0-1]]: [../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../BB/BB/BB/BB/BB/BB/BB/BB/BB/BB][../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..]
[habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh:54105] MCW rank 4 bound to socket 1[core 40[hwt 0-1]], socket 1[core 41[hwt 0-1]], socket 1[core 42[hwt 0-1]], socket 1[core 43[hwt 0-1]], socket 1[core 44[hwt 0-1]], socket 1[core 45[hwt 0-1]], socket 1[core 46[hwt 0-1]], socket 1[core 47[hwt 0-1]], socket 1[core 48[hwt 0-1]], socket 1[core 49[hwt 0-1]]: [../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..][BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..]
[habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh:54105] MCW rank 5 bound to socket 1[core 50[hwt 0-1]], socket 1[core 51[hwt 0-1]], socket 1[core 52[hwt 0-1]], socket 1[core 53[hwt 0-1]], socket 1[core 54[hwt 0-1]], socket 1[core 55[hwt 0-1]], socket 1[core 56[hwt 0-1]], socket 1[core 57[hwt 0-1]], socket 1[core 58[hwt 0-1]], socket 1[core 59[hwt 0-1]]: [../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..][../../../../../../../../../../BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/../../../../../../../../../../../../../../../../../../../..]
[habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh:54105] MCW rank 6 bound to socket 1[core 60[hwt 0-1]], socket 1[core 61[hwt 0-1]], socket 1[core 62[hwt 0-1]], socket 1[core 63[hwt 0-1]], socket 1[core 64[hwt 0-1]], socket 1[core 65[hwt 0-1]], socket 1[core 66[hwt 0-1]], socket 1[core 67[hwt 0-1]], socket 1[core 68[hwt 0-1]], socket 1[core 69[hwt 0-1]]: [../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../../../../BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/../../../../../../../../../..]
[habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh:54105] MCW rank 7 bound to socket 1[core 70[hwt 0-1]], socket 1[core 71[hwt 0-1]], socket 1[core 72[hwt 0-1]], socket 1[core 73[hwt 0-1]], socket 1[core 74[hwt 0-1]], socket 1[core 75[hwt 0-1]], socket 1[core 76[hwt 0-1]], socket 1[core 77[hwt 0-1]], socket 1[core 78[hwt 0-1]], socket 1[core 79[hwt 0-1]]: [../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../BB/BB/BB/BB/BB/BB/BB/BB/BB/BB]
[habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh:54105] MCW rank 0 bound to socket 0[core 0[hwt 0-1]], socket 0[core 1[hwt 0-1]], socket 0[core 2[hwt 0-1]], socket 0[core 3[hwt 0-1]], socket 0[core 4[hwt 0-1]], socket 0[core 5[hwt 0-1]], socket 0[core 6[hwt 0-1]], socket 0[core 7[hwt 0-1]], socket 0[core 8[hwt 0-1]], socket 0[core 9[hwt 0-1]]: [BB/BB/BB/BB/BB/BB/BB/BB/BB/BB/../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..][../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../..]
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
| distributed init (rank 5): env://
[W1112 17:46:06.599889517 socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:12345 (errno: 99 - Cannot assign requested address).
| distributed init (rank 3): env://
[W1112 17:46:06.626403425 socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:12345 (errno: 99 - Cannot assign requested address).
| distributed init (rank 7): env://
[W1112 17:46:06.650986463 socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:12345 (errno: 99 - Cannot assign requested address).
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(object, types.FunctionType)
| distributed init (rank 2): env://
[W1112 17:46:06.788896829 socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:12345 (errno: 99 - Cannot assign requested address).
| distributed init (rank 4): env://
[W1112 17:46:06.927309029 socket.cpp:697] [c10d] The client socket has failed to connect to [localhost]:12345 (errno: 99 - Cannot assign requested address).
| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 6): env://
Namespace(data_path='/scratch/habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh', dl_time_exclude=False, model='resnet50', device='hpu', batch_size=256, epochs=90, epochs_between_evals=1, eval_offset_epochs=0, dl_worker_type='HABANA', workers=10, process_per_node=8, hls_type='HLS1', lr=0.1, lars_base_learning_rate=9.0, lars_end_learning_rate=0.0001, lars_warmup_epochs=3, lars_decay_epochs=36, momentum=0.9, weight_decay=0.0001, lars_weight_decay=5e-05, lr_step_size=30, custom_lr_values=[0.275, 0.45, 0.625, 0.8, 0.08, 0.008, 0.0008], custom_lr_milestones=[1, 2, 3, 4, 30, 60, 80], lr_gamma=0.1, label_smoothing=0.0, print_freq=1, output_dir='.', channels_last=False, resume='', start_epoch=0, seed=123, cache_dataset=False, sync_bn=False, test_only=False, pretrained=False, use_torch_compile=True, no_compiled_autograd=False, hpu_graphs=True, optimizer='sgd', enable_tensorboard_logging=False, force_native_sgd=False, apex=False, apex_opt_level='O1', world_size=8, dist_url='env://', num_train_steps=9223372036854775807, num_eval_steps=9223372036854775807, save_checkpoint=False, save_model=False, run_lazy_mode=False, deterministic=True, profile=False, profile_steps='0', is_autocast=True, rank=0, local_rank=0, distributed=True, dist_backend='hccl')
Loading data
Loading training data
Took 2.11808443069458
Loading validation data
Creating samplers
MediaPipe device legacy device_type legacy device_id 0 pipe_name ResnetMediaPipe:1
============================= HABANA PT BRIDGE CONFIGURATION =========================== 
 PT_HPU_LAZY_MODE = 0
 PT_RECIPE_CACHE_PATH = 
 PT_CACHE_FOLDER_DELETE = 0
 PT_HPU_RECIPE_CACHE_CONFIG = 
 PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807
 PT_HPU_LAZY_ACC_PAR_MODE = 1
 PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0
 PT_HPU_EAGER_PIPELINE_ENABLE = 1
 PT_HPU_EAGER_COLLECTIVE_PIPELINE_ENABLE = 1
---------------------------: System Configuration :---------------------------
Num CPU Cores : 160
CPU RAM       : 2113406920 KB
------------------------------------------------------------------------------
Finding classes ... Done!
Done!
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Generating labels ... Done!
Total media files/labels 1281167 classes 1000
num_slices 8 slice_index 0
random seed used  123
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
sliced media files/labels 160146
Finding largest file ...
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
largest file is  /scratch/habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh/train/n02490219/n02490219_11648.JPEG
Running with Media API DataLoader
MediaPipe device legacy device_type legacy device_id 0 pipe_name ResnetMediaPipe:2
Finding classes ... Done!
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Done!
Generating labels ... Done!
Total media files/labels 50000 classes 1000
num_slices 8 slice_index 0
random seed used  123
sliced media files/labels 6250
Finding largest file ...
largest file is  /scratch/habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh/val/n01630670/ILSVRC2012_val_00046430.JPEG
Running with Media API DataLoader
Creating model
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Start training
terminate called without an active exception
Internal Error: Received signal - Aborted
terminate called without an active exception
Internal Error: Received signal - Aborted
terminate called without an active exception
Internal Error: Received signal - Aborted
terminate called without an active exception
Internal Error: Received signal - Aborted
terminate called without an active exception
Internal Error: Received signal - Aborted
terminate called without an active exception
Internal Error: Received signal - Aborted
terminate called without an active exception
Internal Error: Received signal - Aborted
terminate called without an active exception
Internal Error: Received signal - Aborted
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun noticed that process rank 4 with PID 0 on node habana-resnet-50-ilsvrc-2012-pt240-g1180-u2204-8h225a-mblrh exited on signal 6 (Aborted).
--------------------------------------------------------------------------
real 34.36
user 87.73
sys 50.49
mkandes@vgr-1-20:~$
```
Fixed the above issue by increasing the `hugepages-2Mi` from `12000Mi` to `96000Mi` for the 8-Gaudi2 configruation.
